# 业务服务模块

**功能职责：**

本模块是`website-scanner`的核心，包含了所有具体的业务逻辑实现。每个服务都封装了一组相关的功能，供API层或异步任务调用。

## 文件说明

- `__init__.py`: Python包标识文件。
- `crawler.py`: **网站爬虫服务**
  - 负责根据给定的URL和配置（如爬取深度、并发数、User-Agent）抓取网站的HTML内容。
  - 使用`httpx`进行异步HTTP请求。
  - 解析HTML，提取页面中的所有链接，并进行去重和规范化。
  - 实现一个队列来管理待爬取的URL，并控制爬取的广度或深度。
- `content_checker.py`: **内容检测服务**
  - 接收HTML内容作为输入。
  - 实现多种检测逻辑：
    - **敏感词检测**: 从配置中加载敏感词库，使用正则表达式或Aho-Corasick算法在文本中进行高效匹配。
    - **外链检测**: 提取所有`<a>`标签的`href`属性，识别并检查外部链接的有效性和合规性。
    - **图片内容检测**: (可选) 提取`<img>`标签的`src`，下载图片并调用第三方图像识别API进行分析。
- `beian_checker.py`: **备案查询服务**
  - 接收域名作为输入。
  - 调用第三方API（如阿里云、腾讯云提供的备案查询接口）或通过爬虫模拟查询，获取网站的ICP备案信息。
- `scan_manager.py`: **扫描管理服务**
  - 这是一个更高层次的服务，负责协调其他服务来完成一个完整的扫描任务。
  - 它会创建一个`ScanTask`记录，然后调用`crawler`服务获取页面，将页面内容传递给`content_checker`，并将结果保存到数据库。

## 开发规范

- **单一职责原则**: 每个服务类应只关注一项核心职责（如`Crawler`只负责爬取，`ContentChecker`只负责检测）。
- **无状态**: 服务本身应该是无状态的。所有需要持久化的状态都应通过数据库模型来管理。服务的实例化不应该依赖于之前的调用。
- **依赖注入**: 服务之间的依赖关系（如`ScanManager`依赖`Crawler`和`ContentChecker`）应该通过构造函数注入，而不是在服务内部直接实例化依赖，这有利于测试和解耦。
- **接口化**: (可选，但推荐) 可以为每个服务定义一个抽象基类（ABC），明确其公共接口，使得可以轻松替换实现（如用一个模拟的`Crawler`进行测试）。
- **异步设计**: 所有涉及I/O操作（网络请求、数据库访问）的方法都必须是异步的（`async def`）。