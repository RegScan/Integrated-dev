"""
çœŸå®ç½‘ç«™æ‰«ææµ‹è¯•
æµ‹è¯•æ‰«ææœåŠ¡å¯¹çœŸå®ç½‘ç«™çš„æ£€æµ‹èƒ½åŠ›
"""

import pytest
import time
import logging
import os
from pathlib import Path
from app.services.scan_service import ScanService
from app.services.content_checker import ContentCheckerService

# è·å–å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
current_dir = Path(__file__).parent
log_file = current_dir / "real_scanner_test.log"

# å¼ºåˆ¶é…ç½®æ—¥å¿—
logging.getLogger().handlers.clear()  # æ¸…é™¤ç°æœ‰å¤„ç†å™¨
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(log_file, mode='w', encoding='utf-8')
    ],
    force=True  # å¼ºåˆ¶é‡æ–°é…ç½®
)
logger = logging.getLogger(__name__)


class TestRealScanner:
    """çœŸå®ç½‘ç«™æ‰«ææµ‹è¯•ç±»"""
    
    @pytest.fixture
    def scan_service(self):
        """åˆ›å»ºæ‰«ææœåŠ¡"""
        logger.info("ğŸ”§ åˆ›å»ºæ‰«ææœåŠ¡...")
        return ScanService(api_key="test_key")
    
    @pytest.fixture
    def content_checker(self):
        """åˆ›å»ºå†…å®¹æ£€æµ‹æœåŠ¡"""
        logger.info("ğŸ”§ åˆ›å»ºå†…å®¹æ£€æµ‹æœåŠ¡...")
        return ContentCheckerService(api_key="test_key")
    
    @pytest.mark.real_website
    @pytest.mark.slow
    def test_real_website_compliance_check(self, scan_service, real_website_list):
        """æµ‹è¯•çœŸå®ç½‘ç«™åˆè§„æ£€æµ‹"""
        logger.info("ğŸš€ å¼€å§‹çœŸå®ç½‘ç«™åˆè§„æ£€æµ‹æµ‹è¯•")
        
        successful_checks = 0
        total_checks = min(3, len(real_website_list))  # åªæµ‹è¯•å‰3ä¸ªç½‘ç«™
        
        for i in range(total_checks):
            website = real_website_list[i]
            domain = website["domain"]
            description = website["description"]
            expected = website["expected_compliant"]
            
            logger.info(f"ğŸ“Š è¿›åº¦: {i+1}/{total_checks} - æ­£åœ¨æ£€æµ‹: {domain} ({description})")
            
            try:
                start_time = time.time()
                result = scan_service.check_compliance(domain)
                end_time = time.time()
                
                duration = end_time - start_time
                
                assert result is not None, f"æ£€æµ‹å¤±è´¥: {domain}"
                assert "domain" in result, f"ç¼ºå°‘åŸŸåä¿¡æ¯: {domain}"
                assert "compliant" in result, f"ç¼ºå°‘åˆè§„çŠ¶æ€: {domain}"
                
                logger.info(f"âœ… {domain} æ£€æµ‹å®Œæˆ")
                logger.info(f"   â±ï¸ æ£€æµ‹æ—¶é—´: {duration:.2f} ç§’")
                logger.info(f"   ğŸ“Š åˆè§„çŠ¶æ€: {result['compliant']}")
                logger.info(f"   ğŸ¯ é¢„æœŸçŠ¶æ€: {expected}")
                
                # æ³¨æ„ï¼šçœŸå®ç½‘ç«™çš„åˆè§„çŠ¶æ€å¯èƒ½å˜åŒ–ï¼Œè¿™é‡ŒåªåšåŸºæœ¬éªŒè¯
                assert isinstance(result["compliant"], bool)
                successful_checks += 1
                
            except Exception as e:
                logger.error(f"âŒ {domain} æ£€æµ‹å¤±è´¥: {e}")
                # çœŸå®ç½‘ç«™å¯èƒ½å¶å°”å¤±è´¥ï¼Œè¿™æ˜¯æ­£å¸¸çš„
                continue
            
            if i < total_checks - 1:
                logger.info("â³ ç­‰å¾… 5 ç§’åç»§ç»­...")
                time.sleep(5)  # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
        
        success_rate = successful_checks / total_checks
        logger.info(f"ğŸ“ˆ åˆè§„æ£€æµ‹æµ‹è¯•å®Œæˆ: {successful_checks}/{total_checks} æˆåŠŸ ({success_rate:.1%})")
    
    @pytest.mark.violation_test
    @pytest.mark.slow
    def test_violation_website_compliance_check(self, scan_service, violation_website_list):
        """æµ‹è¯•è¿è§„ç½‘ç«™åˆè§„æ£€æµ‹"""
        logger.info("ğŸš€ å¼€å§‹è¿è§„ç½‘ç«™åˆè§„æ£€æµ‹æµ‹è¯•")
        
        successful_checks = 0
        total_checks = len(violation_website_list)
        
        for i, website in enumerate(violation_website_list, 1):
            domain = website["domain"]
            description = website["description"]
            expected = website["expected_compliant"]
            violation_type = website["violation_type"]
            test_content = website["test_content"]
            
            logger.info(f"ğŸ“Š è¿›åº¦: {i}/{total_checks} - æ­£åœ¨æ£€æµ‹è¿è§„ç½‘ç«™: {domain} ({description})")
            logger.info(f"   ğŸš¨ è¿è§„ç±»å‹: {violation_type}")
            logger.info(f"   ğŸ“ æµ‹è¯•å†…å®¹: {test_content}")
            
            try:
                # ç”±äºè¿è§„ç½‘ç«™åŸŸåä¸å­˜åœ¨ï¼Œæˆ‘ä»¬æ¨¡æ‹Ÿæ£€æµ‹è¿‡ç¨‹
                # ç›´æ¥æµ‹è¯•å†…å®¹æ£€æµ‹åŠŸèƒ½
                from app.services.content_checker import ContentCheckerService
                content_checker = ContentCheckerService(api_key="test_key")
                
                start_time = time.time()
                text_result = content_checker._check_text(test_content)
                end_time = time.time()
                
                duration = end_time - start_time
                
                # æ¨¡æ‹Ÿæ‰«æç»“æœ
                result = {
                    "domain": domain,
                    "compliant": text_result.get("compliant", True),
                    "text_result": text_result,
                    "image_results": [],
                    "violation_type": violation_type,
                    "test_content": test_content
                }
                
                logger.info(f"âœ… {domain} è¿è§„æ£€æµ‹å®Œæˆ")
                logger.info(f"   â±ï¸ æ£€æµ‹æ—¶é—´: {duration:.2f} ç§’")
                logger.info(f"   ğŸ“Š åˆè§„çŠ¶æ€: {result['compliant']}")
                logger.info(f"   ğŸ¯ é¢„æœŸçŠ¶æ€: {expected}")
                logger.info(f"   ğŸš¨ è¿è§„ç±»å‹: {violation_type}")
                
                # éªŒè¯æ£€æµ‹ç»“æœ
                assert isinstance(result["compliant"], bool)
                successful_checks += 1
                
            except Exception as e:
                logger.error(f"âŒ {domain} è¿è§„æ£€æµ‹å¤±è´¥: {e}")
                continue
        
        success_rate = successful_checks / total_checks
        logger.info(f"ğŸ“ˆ è¿è§„ç½‘ç«™æ£€æµ‹æµ‹è¯•å®Œæˆ: {successful_checks}/{total_checks} æˆåŠŸ ({success_rate:.1%})")
    
    @pytest.mark.violation_test
    @pytest.mark.slow
    def test_violation_detection_accuracy(self, content_checker, violation_content_samples):
        """æµ‹è¯•è¿è§„æ£€æµ‹å‡†ç¡®æ€§"""
        logger.info("ğŸš€ å¼€å§‹è¿è§„æ£€æµ‹å‡†ç¡®æ€§æµ‹è¯•")
        
        total_tests = 0
        correct_detections = 0
        
        for violation_type, content_samples in violation_content_samples.items():
            logger.info(f"ğŸ¯ æµ‹è¯•è¿è§„ç±»å‹: {violation_type}")
            
            for i, content in enumerate(content_samples, 1):
                total_tests += 1
                logger.info(f"   ğŸ“ æµ‹è¯•å†…å®¹ {i}: {content[:50]}...")
                
                try:
                    # æ£€æµ‹æ–‡æœ¬å†…å®¹
                    result = content_checker._check_text(content)
                    actual_compliant = result.get("compliant", True)
                    
                    # è¿è§„å†…å®¹åº”è¯¥è¢«æ£€æµ‹ä¸ºä¸åˆè§„
                    expected_compliant = False  # è¿è§„å†…å®¹é¢„æœŸä¸ºFalse
                    
                    if actual_compliant == expected_compliant:
                        logger.info(f"   âœ… æ£€æµ‹ç»“æœæ­£ç¡®")
                        correct_detections += 1
                    else:
                        logger.warning(f"   âš ï¸ æ£€æµ‹ç»“æœé”™è¯¯")
                        logger.warning(f"   ğŸ“Š å®é™…ç»“æœ: {actual_compliant}, é¢„æœŸ: {expected_compliant}")
                    
                    logger.info(f"   ğŸ“Š æ£€æµ‹ç»“æœ: {result}")
                    
                except Exception as e:
                    logger.error(f"   âŒ æ£€æµ‹å¤±è´¥: {e}")
        
        accuracy_rate = correct_detections / total_tests if total_tests > 0 else 0
        logger.info(f"ğŸ“ˆ è¿è§„æ£€æµ‹å‡†ç¡®æ€§æµ‹è¯•å®Œæˆ: {correct_detections}/{total_tests} æ­£ç¡® ({accuracy_rate:.1%})")
        
        # éªŒè¯æµ‹è¯•æ¡†æ¶æ­£å¸¸å·¥ä½œ
        assert total_tests > 0, "æ²¡æœ‰æ‰§è¡Œä»»ä½•è¿è§„æ£€æµ‹æµ‹è¯•"
    
    @pytest.mark.real_website
    @pytest.mark.slow
    def test_real_website_content_analysis(self, content_checker):
        """æµ‹è¯•çœŸå®ç½‘ç«™å†…å®¹åˆ†æ"""
        logger.info("ğŸš€ å¼€å§‹çœŸå®ç½‘ç«™å†…å®¹åˆ†ææµ‹è¯•")
        
        domain = "bing.com"
        logger.info(f"ğŸ¯ ç›®æ ‡ç½‘ç«™: {domain}")
        
        # å…ˆçˆ¬å–ç½‘ç«™å†…å®¹
        logger.info("ğŸ•·ï¸ å¼€å§‹çˆ¬å–ç½‘ç«™å†…å®¹...")
        from app.services.crawler import CrawlerService
        crawler = CrawlerService()
        website_data = crawler.crawl_website(domain)
        
        if website_data is None:
            logger.error("âŒ çˆ¬å–å¤±è´¥")
            pytest.skip("æ— æ³•çˆ¬å–ç½‘ç«™å†…å®¹")
        
        logger.info(f"âœ… ç½‘ç«™çˆ¬å–æˆåŠŸ")
        logger.info(f"   ğŸ“ æ–‡æœ¬é•¿åº¦: {len(website_data['text'])} å­—ç¬¦")
        logger.info(f"   ğŸ–¼ï¸ å›¾ç‰‡æ•°é‡: {len(website_data['images'])} å¼ ")
        
        # åˆ†ææ–‡æœ¬å†…å®¹
        logger.info("ğŸ” å¼€å§‹åˆ†ææ–‡æœ¬å†…å®¹...")
        text_result = content_checker._check_text(website_data["text"])
        assert text_result is not None
        
        logger.info(f"ğŸ“Š æ–‡æœ¬åˆ†æç»“æœ: {text_result}")
        
        # åˆ†æå›¾ç‰‡å†…å®¹ï¼ˆå¦‚æœæœ‰ï¼‰
        if website_data["images"]:
            logger.info("ğŸ–¼ï¸ å¼€å§‹åˆ†æå›¾ç‰‡å†…å®¹...")
            for i, img_url in enumerate(website_data["images"][:2], 1):  # åªæµ‹è¯•å‰2å¼ å›¾ç‰‡
                logger.info(f"   ğŸ“¸ åˆ†æå›¾ç‰‡ {i}: {img_url}")
                img_result = content_checker._check_image(img_url)
                logger.info(f"   ğŸ“Š å›¾ç‰‡åˆ†æç»“æœ: {img_result}")
        else:
            logger.info("â„¹ï¸ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡å†…å®¹")
        
        logger.info("âœ… å†…å®¹åˆ†ææµ‹è¯•å®Œæˆ")
    
    @pytest.mark.violation_test
    @pytest.mark.slow
    def test_violation_content_analysis(self, content_checker, violation_content_samples):
        """æµ‹è¯•è¿è§„å†…å®¹åˆ†æ"""
        logger.info("ğŸš€ å¼€å§‹è¿è§„å†…å®¹åˆ†ææµ‹è¯•")
        
        total_analyzed = 0
        violation_detected = 0
        
        for violation_type, content_samples in violation_content_samples.items():
            logger.info(f"ğŸ¯ åˆ†æè¿è§„ç±»å‹: {violation_type}")
            
            for i, content in enumerate(content_samples, 1):
                total_analyzed += 1
                logger.info(f"   ğŸ“ åˆ†æå†…å®¹ {i}: {content[:50]}...")
                
                try:
                    # æ£€æµ‹æ–‡æœ¬å†…å®¹
                    result = content_checker._check_text(content)
                    
                    if result and not result.get("compliant", True):
                        logger.info(f"   âœ… æˆåŠŸæ£€æµ‹åˆ°è¿è§„å†…å®¹")
                        violation_detected += 1
                    else:
                        logger.warning(f"   âš ï¸ æœªæ£€æµ‹åˆ°è¿è§„å†…å®¹")
                    
                    logger.info(f"   ğŸ“Š æ£€æµ‹ç»“æœ: {result}")
                    
                except Exception as e:
                    logger.error(f"   âŒ æ£€æµ‹å¤±è´¥: {e}")
        
        detection_rate = violation_detected / total_analyzed if total_analyzed > 0 else 0
        logger.info(f"ğŸ“ˆ è¿è§„å†…å®¹åˆ†ææµ‹è¯•å®Œæˆ: {violation_detected}/{total_analyzed} æ£€æµ‹åˆ°è¿è§„ ({detection_rate:.1%})")
        
        # éªŒè¯åˆ†ææ¡†æ¶æ­£å¸¸å·¥ä½œ
        assert total_analyzed > 0, "æ²¡æœ‰æ‰§è¡Œä»»ä½•å†…å®¹åˆ†æ"
    
    @pytest.mark.real_website
    @pytest.mark.slow
    def test_real_website_scan_performance(self, scan_service):
        """æµ‹è¯•æ‰«ææ€§èƒ½"""
        logger.info("ğŸš€ å¼€å§‹æ‰«ææ€§èƒ½æµ‹è¯•")
        
        domain = "bing.com"
        logger.info(f"ğŸ¯ ç›®æ ‡ç½‘ç«™: {domain}")
        
        start_time = time.time()
        result = scan_service.check_compliance(domain)
        end_time = time.time()
        
        duration = end_time - start_time
        
        logger.info(f"ğŸ“Š æ‰«ææ€§èƒ½æµ‹è¯•:")
        logger.info(f"   ğŸŒ ç½‘ç«™: {domain}")
        logger.info(f"   â±ï¸ æ‰«ææ—¶é—´: {duration:.2f} ç§’")
        
        if result:
            logger.info(f"   ğŸ“Š åˆè§„çŠ¶æ€: {result.get('compliant', 'N/A')}")
            logger.info(f"   ğŸ“ æ–‡æœ¬ç»“æœ: {result.get('text_result', 'N/A')}")
            logger.info(f"   ğŸ–¼ï¸ å›¾ç‰‡ç»“æœæ•°é‡: {len(result.get('image_results', []))}")
            
            # æ€§èƒ½è¦æ±‚ï¼šæ‰«ææ—¶é—´åº”è¯¥åœ¨åˆç†èŒƒå›´å†…
            assert duration < 60, f"æ‰«ææ—¶é—´è¿‡é•¿: {duration} ç§’"
            logger.info("âœ… æ‰«ææ€§èƒ½æµ‹è¯•é€šè¿‡")
        else:
            logger.warning("âš ï¸ æ‰«æå¤±è´¥ï¼Œä½†éªŒè¯äº†è¶…æ—¶æœºåˆ¶")
            # å¦‚æœæ‰«æå¤±è´¥ï¼Œè‡³å°‘éªŒè¯è¶…æ—¶æ—¶é—´åˆç†
            assert duration < 60, f"è¶…æ—¶æ—¶é—´è¿‡é•¿: {duration} ç§’"
    
    @pytest.mark.real_website
    @pytest.mark.slow
    def test_real_website_scan_error_handling(self, scan_service, invalid_domains):
        """æµ‹è¯•æ‰«æé”™è¯¯å¤„ç†"""
        logger.info("ğŸš€ å¼€å§‹æ‰«æé”™è¯¯å¤„ç†æµ‹è¯•")
        
        for i, domain in enumerate(invalid_domains, 1):
            logger.info(f"ğŸ“Š è¿›åº¦: {i}/{len(invalid_domains)} - æµ‹è¯•æ— æ•ˆåŸŸåæ‰«æ: {domain}")
            
            start_time = time.time()
            result = scan_service.check_compliance(domain)
            end_time = time.time()
            
            duration = end_time - start_time
            
            if result and result.get("status") == "error":
                logger.info(f"âœ… {domain} æ­£ç¡®å¤„ç†äº†æ‰«æé”™è¯¯")
            else:
                logger.warning(f"âš ï¸ {domain} æ‰«æç»“æœå¼‚å¸¸")
            
            logger.info(f"   â±ï¸ å¤„ç†æ—¶é—´: {duration:.2f} ç§’")
        
        logger.info("âœ… æ‰«æé”™è¯¯å¤„ç†æµ‹è¯•å®Œæˆ")
    
    @pytest.mark.real_website
    @pytest.mark.slow
    def test_real_website_scan_data_storage(self, scan_service):
        """æµ‹è¯•æ‰«ææ•°æ®å­˜å‚¨"""
        logger.info("ğŸš€ å¼€å§‹æ‰«ææ•°æ®å­˜å‚¨æµ‹è¯•")
        
        domain = "bing.com"
        logger.info(f"ğŸ¯ ç›®æ ‡ç½‘ç«™: {domain}")
        
        result = scan_service.check_compliance(domain)
        if result is None:
            logger.error("âŒ æ‰«æå¤±è´¥")
            pytest.skip("æ— æ³•å®Œæˆæ‰«æ")
        
        # éªŒè¯å­˜å‚¨çš„æ•°æ®ç»“æ„
        assert "domain" in result
        assert "compliant" in result
        assert "text_result" in result
        assert "image_results" in result
        assert "timestamp" in result
        
        logger.info(f"ğŸ“Š æ•°æ®å­˜å‚¨éªŒè¯:")
        logger.info(f"   ğŸŒ åŸŸå: {result['domain']}")
        logger.info(f"   ğŸ“Š åˆè§„çŠ¶æ€: {result['compliant']}")
        logger.info(f"   â° æ—¶é—´æˆ³: {result['timestamp']}")
        logger.info(f"   ğŸ“ æ–‡æœ¬ç»“æœ: {result['text_result']}")
        logger.info(f"   ğŸ–¼ï¸ å›¾ç‰‡ç»“æœæ•°é‡: {len(result['image_results'])}")
        logger.info("âœ… æ•°æ®å­˜å‚¨æµ‹è¯•å®Œæˆ")
    
    @pytest.mark.real_website
    @pytest.mark.slow
    def test_real_website_scan_concurrent(self, scan_service):
        """æµ‹è¯•å¹¶å‘æ‰«æ"""
        logger.info("ğŸš€ å¼€å§‹å¹¶å‘æ‰«ææµ‹è¯•")
        
        domains = ["bing.com", "httpbin.org"]
        logger.info(f"ğŸ¯ ç›®æ ‡ç½‘ç«™: {domains}")
        
        logger.info("ğŸ”„ å¼€å§‹å¹¶å‘æ‰«æ...")
        
        start_time = time.time()
        results = []
        
        for i, domain in enumerate(domains, 1):
            logger.info(f"ğŸ“Š è¿›åº¦: {i}/{len(domains)} - æ‰«æ {domain}")
            try:
                result = scan_service.check_compliance(domain)
                results.append(result)
                logger.info(f"   âœ… {domain} æ‰«æå®Œæˆ")
            except Exception as e:
                logger.error(f"   âŒ {domain} æ‰«æå¤±è´¥: {e}")
        
        end_time = time.time()
        total_time = end_time - start_time
        
        logger.info(f"ğŸ“ˆ å¹¶å‘æ‰«æç»“æœ:")
        logger.info(f"   â±ï¸ æ€»æ—¶é—´: {total_time:.2f} ç§’")
        logger.info(f"   âœ… æˆåŠŸæ•°é‡: {len(results)}")
        logger.info(f"   ğŸ“Š å¹³å‡æ—¶é—´: {total_time/len(domains):.2f} ç§’/ç½‘ç«™")
        
        assert len(results) > 0, "æ²¡æœ‰æˆåŠŸçš„æ‰«æ"
        logger.info("âœ… å¹¶å‘æ‰«ææµ‹è¯•å®Œæˆ") 